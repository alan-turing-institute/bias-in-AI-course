{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMuRYKtj4SHR"
   },
   "source": [
    "# **Milestone 3: Sources, Forms, and Quantification of Bias and Discrimination in Supervised Learning**\n",
    "## **PRACTICE NOTEBOOK 3 - Evaluate model bias using holisticai library**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0v83HDaM4g99"
   },
   "source": [
    "In this part of the course, we will look for bias using a practical example. A  company is looking to hire a new employee. They use a machine learning algorithm to select the top candidates. The candidates are assigned either 0 if they're not selected or 1 if they are. \n",
    "\n",
    "There are 4 practice notebooks in total (current one in red):\n",
    "1. Explore given data to: detect potential bias early & check for proxies \n",
    "2. Evaluate model bias \"manually\"\n",
    "3. <font color='red'> **Evaluate model bias using **holisticai** library**</font>\n",
    "4. Example code to get confidence intervals for a metric (nothing to do)\n",
    "\n",
    "Instructions to complete in each parts are in bold. Intermediate results are given so one can continue the exercise. \n",
    "\n",
    "This is notebook number 3. In the previous notebook, we measured bias manually. There exist a number of python library facilitating calculations for us. In this part, we will replicate the results found in the previous section using holisticai. In this notebook, we will:\n",
    "- Import data and useful modules\n",
    "- Install and import holisticai\n",
    "- Learn how to calculate fairness metrics using holisticai\n",
    "\n",
    "We evaluate here the same metrics as in the previous notebook. You should get the same results as what you calculated \"manually\" in notebook 2. Here we only work with the \"Black\" unprivileged group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nYt5_h77QGN"
   },
   "source": [
    "## **0 - Import modules, load data and useful functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "KgfZWXdy1REj"
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "ClEzlOOOpr0B",
    "outputId": "03766f65-a122-4809-c3f9-40dec57adadb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>-0.178832</td>\n",
       "      <td>0.147077</td>\n",
       "      <td>0.775331</td>\n",
       "      <td>-0.427889</td>\n",
       "      <td>0.640818</td>\n",
       "      <td>-0.610427</td>\n",
       "      <td>-1.023371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513206</td>\n",
       "      <td>-0.042387</td>\n",
       "      <td>-0.355889</td>\n",
       "      <td>-0.465837</td>\n",
       "      <td>-2.832634</td>\n",
       "      <td>0.917297</td>\n",
       "      <td>-0.241052</td>\n",
       "      <td>-2.122105</td>\n",
       "      <td>0.253170</td>\n",
       "      <td>0.164617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.092276</td>\n",
       "      <td>0.122023</td>\n",
       "      <td>0.482935</td>\n",
       "      <td>-0.232131</td>\n",
       "      <td>-1.939064</td>\n",
       "      <td>-1.140216</td>\n",
       "      <td>-0.833250</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.203151</td>\n",
       "      <td>0.750136</td>\n",
       "      <td>-1.417751</td>\n",
       "      <td>1.254152</td>\n",
       "      <td>0.631731</td>\n",
       "      <td>1.665469</td>\n",
       "      <td>-0.388293</td>\n",
       "      <td>-0.804782</td>\n",
       "      <td>-0.227182</td>\n",
       "      <td>0.412375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>-1.703377</td>\n",
       "      <td>-0.962149</td>\n",
       "      <td>-0.785495</td>\n",
       "      <td>-0.633902</td>\n",
       "      <td>-0.334718</td>\n",
       "      <td>-1.555958</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249654</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.079523</td>\n",
       "      <td>-0.932425</td>\n",
       "      <td>-0.693293</td>\n",
       "      <td>-0.114197</td>\n",
       "      <td>-1.252067</td>\n",
       "      <td>0.834270</td>\n",
       "      <td>-0.463270</td>\n",
       "      <td>0.559294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.229715</td>\n",
       "      <td>-1.342997</td>\n",
       "      <td>-0.093382</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>1.195076</td>\n",
       "      <td>-0.582687</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667730</td>\n",
       "      <td>0.595494</td>\n",
       "      <td>0.454502</td>\n",
       "      <td>-0.366884</td>\n",
       "      <td>-0.399758</td>\n",
       "      <td>1.113102</td>\n",
       "      <td>0.126707</td>\n",
       "      <td>0.474569</td>\n",
       "      <td>-0.158103</td>\n",
       "      <td>1.197710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>-0.363013</td>\n",
       "      <td>1.264307</td>\n",
       "      <td>1.667603</td>\n",
       "      <td>0.903941</td>\n",
       "      <td>-0.062840</td>\n",
       "      <td>0.680886</td>\n",
       "      <td>0.389930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494161</td>\n",
       "      <td>0.784050</td>\n",
       "      <td>-0.311236</td>\n",
       "      <td>2.447118</td>\n",
       "      <td>1.127650</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>-0.381553</td>\n",
       "      <td>0.209684</td>\n",
       "      <td>0.197809</td>\n",
       "      <td>-0.879914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>-0.057075</td>\n",
       "      <td>1.791513</td>\n",
       "      <td>-1.065756</td>\n",
       "      <td>-0.783341</td>\n",
       "      <td>-0.559215</td>\n",
       "      <td>1.042646</td>\n",
       "      <td>-1.154058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335082</td>\n",
       "      <td>0.709753</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>1.718576</td>\n",
       "      <td>1.171804</td>\n",
       "      <td>0.430075</td>\n",
       "      <td>3.340726</td>\n",
       "      <td>1.349216</td>\n",
       "      <td>1.481516</td>\n",
       "      <td>0.070563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>0.582066</td>\n",
       "      <td>0.086788</td>\n",
       "      <td>0.167259</td>\n",
       "      <td>-1.672798</td>\n",
       "      <td>1.537135</td>\n",
       "      <td>-1.113315</td>\n",
       "      <td>0.222907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562594</td>\n",
       "      <td>0.150314</td>\n",
       "      <td>-0.072920</td>\n",
       "      <td>-1.841719</td>\n",
       "      <td>-0.807065</td>\n",
       "      <td>-0.793955</td>\n",
       "      <td>-1.098300</td>\n",
       "      <td>-1.474154</td>\n",
       "      <td>-0.828826</td>\n",
       "      <td>-0.891166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>-1.355098</td>\n",
       "      <td>-0.321228</td>\n",
       "      <td>-0.204290</td>\n",
       "      <td>0.498632</td>\n",
       "      <td>1.634130</td>\n",
       "      <td>0.847070</td>\n",
       "      <td>-0.552140</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.204719</td>\n",
       "      <td>0.688433</td>\n",
       "      <td>-1.781911</td>\n",
       "      <td>0.275032</td>\n",
       "      <td>0.690859</td>\n",
       "      <td>0.666878</td>\n",
       "      <td>0.644440</td>\n",
       "      <td>0.127891</td>\n",
       "      <td>1.277781</td>\n",
       "      <td>-0.744428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.526557</td>\n",
       "      <td>2.174463</td>\n",
       "      <td>-0.979082</td>\n",
       "      <td>-0.681536</td>\n",
       "      <td>-0.145515</td>\n",
       "      <td>1.703135</td>\n",
       "      <td>0.947010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487367</td>\n",
       "      <td>2.043764</td>\n",
       "      <td>-1.570147</td>\n",
       "      <td>0.861712</td>\n",
       "      <td>-0.939181</td>\n",
       "      <td>0.090775</td>\n",
       "      <td>-1.153183</td>\n",
       "      <td>-1.362903</td>\n",
       "      <td>-1.424866</td>\n",
       "      <td>-0.374579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.878986</td>\n",
       "      <td>0.750031</td>\n",
       "      <td>1.014081</td>\n",
       "      <td>-0.324345</td>\n",
       "      <td>0.778664</td>\n",
       "      <td>-0.469189</td>\n",
       "      <td>0.750975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.118061</td>\n",
       "      <td>-0.708493</td>\n",
       "      <td>0.323589</td>\n",
       "      <td>-1.607874</td>\n",
       "      <td>-0.218238</td>\n",
       "      <td>0.104560</td>\n",
       "      <td>-1.013426</td>\n",
       "      <td>0.563411</td>\n",
       "      <td>-0.399798</td>\n",
       "      <td>-0.021546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Gender Ethnicity         0         1         2         3  \\\n",
       "0       1.0  Female     Black -0.178832  0.147077  0.775331 -0.427889   \n",
       "1       1.0    Male  Hispanic  0.092276  0.122023  0.482935 -0.232131   \n",
       "2       0.0  Female  Hispanic -1.703377 -0.962149 -0.785495 -0.633902   \n",
       "3       0.0    None      None -1.229715 -1.342997 -0.093382  0.136900   \n",
       "4       1.0    Male  Hispanic -0.363013  1.264307  1.667603  0.903941   \n",
       "...     ...     ...       ...       ...       ...       ...       ...   \n",
       "9995    1.0  Female  Hispanic -0.057075  1.791513 -1.065756 -0.783341   \n",
       "9996    1.0    Male     Black  0.582066  0.086788  0.167259 -1.672798   \n",
       "9997    0.0    Male     White -1.355098 -0.321228 -0.204290  0.498632   \n",
       "9998    1.0    Male     White -0.526557  2.174463 -0.979082 -0.681536   \n",
       "9999    0.0    None      None  0.878986  0.750031  1.014081 -0.324345   \n",
       "\n",
       "             4         5         6  ...        40        41        42  \\\n",
       "0     0.640818 -0.610427 -1.023371  ...  0.513206 -0.042387 -0.355889   \n",
       "1    -1.939064 -1.140216 -0.833250  ... -1.203151  0.750136 -1.417751   \n",
       "2    -0.334718 -1.555958  0.825006  ...  0.249654  0.368800  0.079523   \n",
       "3     1.195076 -0.582687  0.052355  ...  0.667730  0.595494  0.454502   \n",
       "4    -0.062840  0.680886  0.389930  ... -0.494161  0.784050 -0.311236   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995 -0.559215  1.042646 -1.154058  ... -0.335082  0.709753  0.021583   \n",
       "9996  1.537135 -1.113315  0.222907  ... -0.562594  0.150314 -0.072920   \n",
       "9997  1.634130  0.847070 -0.552140  ... -1.204719  0.688433 -1.781911   \n",
       "9998 -0.145515  1.703135  0.947010  ... -0.487367  2.043764 -1.570147   \n",
       "9999  0.778664 -0.469189  0.750975  ...  1.118061 -0.708493  0.323589   \n",
       "\n",
       "            43        44        45        46        47        48        49  \n",
       "0    -0.465837 -2.832634  0.917297 -0.241052 -2.122105  0.253170  0.164617  \n",
       "1     1.254152  0.631731  1.665469 -0.388293 -0.804782 -0.227182  0.412375  \n",
       "2    -0.932425 -0.693293 -0.114197 -1.252067  0.834270 -0.463270  0.559294  \n",
       "3    -0.366884 -0.399758  1.113102  0.126707  0.474569 -0.158103  1.197710  \n",
       "4     2.447118  1.127650  0.086733 -0.381553  0.209684  0.197809 -0.879914  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995  1.718576  1.171804  0.430075  3.340726  1.349216  1.481516  0.070563  \n",
       "9996 -1.841719 -0.807065 -0.793955 -1.098300 -1.474154 -0.828826 -0.891166  \n",
       "9997  0.275032  0.690859  0.666878  0.644440  0.127891  1.277781 -0.744428  \n",
       "9998  0.861712 -0.939181  0.090775 -1.153183 -1.362903 -1.424866 -0.374579  \n",
       "9999 -1.607874 -0.218238  0.104560 -1.013426  0.563411 -0.399798 -0.021546  \n",
       "\n",
       "[10000 rows x 53 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "bunch = fetch_openml(data_id=44270)\n",
    "raw_data = bunch['frame']\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "fo4na9kCw6bN"
   },
   "outputs": [],
   "source": [
    "# remove all nans --> we use the variable \"data\" in the rest of this notebook\n",
    "data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true,y_pred,labels = [1,0],display_labels = [1,0], ax = None):\n",
    "  cm = confusion_matrix(y_true,y_pred,labels = labels)\n",
    "  if ax is None:\n",
    "    fig, ax = plt.subplots()\n",
    "  else:\n",
    "    fig = ax.figure\n",
    "  sns.heatmap(cm, annot=True, ax = ax, cmap='viridis',fmt='g')\n",
    "\n",
    "  ax.set(xticklabels=display_labels,\n",
    "          yticklabels=display_labels,\n",
    "          ylabel=\"True label\",\n",
    "          xlabel=\"Predicted label\")\n",
    "  return cm\n",
    "def split_data_from_df(data):\n",
    "  y = data['Label'].values\n",
    "  # g = data['Gender'].values\n",
    "  # e = data['Ethnicity'].values\n",
    "  X = data[np.arange(50).astype(str)].values\n",
    "  filter_col = ['Ethnicity','Gender'] + [col for col in data if str(col).startswith('Ethnicity_')] + [col for col in data if str(col).startswith('Gender_')] \n",
    "  dem = data[filter_col].copy()\n",
    "  return X,y,dem\n",
    "def encode(df):\n",
    "  g_enc = LabelEncoder()\n",
    "  e_enc = LabelEncoder()\n",
    "  df['Gender'] = g_enc.fit_transform(df['Gender'])\n",
    "  df['Ethnicity'] = e_enc.fit_transform(df['Ethnicity'])\n",
    "  return df, g_enc,e_enc\n",
    "def resample_equal(df,cat):\n",
    "  df['uid'] = df[cat] + df['Label'].astype(str)\n",
    "  enc = LabelEncoder()\n",
    "  df['uid'] = enc.fit_transform(df['uid'])\n",
    "  # Resample\n",
    "  uid = df['uid'].values\n",
    "  res = imblearn.over_sampling.RandomOverSampler(random_state=6)\n",
    "  df_res,euid = res.fit_resample(df,uid)\n",
    "  df_res = pd.DataFrame(df_res,columns = df.columns)\n",
    "  df_res = df_res.sample(frac=1).reset_index(drop=True)\n",
    "  df_res['Label'] = df_res['Label'].astype(float)\n",
    "  return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzvvNPjWL5_-"
   },
   "source": [
    "## **1. Install and import holisticai library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPTo6bhBI52X",
    "outputId": "ebc105af-c4fd-469b-e6d0-b7c29173780c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://test.pypi.org/pypi/, https://pypi.org/simple\n",
      "Requirement already satisfied: holisticai in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (0.20.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from holisticai) (1.1.0)\n",
      "Requirement already satisfied: seaborn>=0.11.2 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from holisticai) (0.11.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=1.0.2->holisticai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=1.0.2->holisticai) (1.22.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=1.0.2->holisticai) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from scikit-learn>=1.0.2->holisticai) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from seaborn>=0.11.2->holisticai) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from seaborn>=0.11.2->holisticai) (3.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (3.0.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (4.33.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from matplotlib>=2.2->seaborn>=0.11.2->holisticai) (9.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/giuliofilippi/Library/Python/3.8/lib/python/site-packages (from pandas>=0.23->seaborn>=0.11.2->holisticai) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn>=0.11.2->holisticai) (1.15.0)\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "# !pip install holisticai \n",
    "!pip3 install holisticai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "TqLHs_GJJBeF"
   },
   "outputs": [],
   "source": [
    "# import some bias metrics\n",
    "from holisticai.bias.metrics import statistical_parity\n",
    "from holisticai.bias.metrics import disparate_impact\n",
    "from holisticai.bias.metrics import equal_opportunity_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV7HUVoiKE0T"
   },
   "source": [
    "## **2. Train the model and get the predictions for the test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFoOaE65KE7r"
   },
   "source": [
    "- **Train the model and get the predictions for the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.69\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "data_train, data_test = train_test_split(data,test_size = 0.3,random_state=4)\n",
    "# get X,y,demographics for each\n",
    "X_train,y_train,dem_train = split_data_from_df(data_train)\n",
    "X_test,y_test,dem_test = split_data_from_df(data_test)\n",
    "# define model and train\n",
    "model = RidgeClassifier(random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "# evaluate on test\n",
    "y_pred_test = model.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred_test)\n",
    "print(\"Accuracy is %.2f\"%acc)\n",
    "# add predictions to data_test for simplicity of analysis\n",
    "data_test = data_test.copy()\n",
    "data_test['Pred'] = y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq0-K1xSKaNy"
   },
   "source": [
    "## **4. Compute fairness metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcIy-8AqpiG2"
   },
   "source": [
    "Now we will need to choose what privileged group and unprivileged group we want to focus on. We will demonstrate for *Black* vs *White*. We define our privileged group and unprivileged group as such. Link to [holisticai](https://holisticai.readthedocs.io/en/latest/metrics.html#binary-classification) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up vectors\n",
    "group_a = data_test.Ethnicity=='Black'\n",
    "group_b = data_test.Ethnicity=='White'\n",
    "y_true = y_test\n",
    "y_pred = y_pred_test\n",
    "\n",
    "# TODO compute fairness metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following\n",
    "\n",
    "| Metric | Value | \n",
    "| --- | --- | \n",
    "| Statistical Parity |-0.11 | \n",
    "| Disparate Impact | 0.67 |\n",
    "| Equal Opportunity Difference | -0.15 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DENBCL2AMc3I"
   },
   "source": [
    "## **Final remarks**\n",
    "**You should find the same results as in the previous section**. \n",
    "\n",
    "Note that for each analysis, we only obtained one number for fairness metrics. As mentioned before, in a real life setting, you should calculate a confidence interval by repeating the experiments for different train/test splits. A way to do this is for instance to use a non-parametric bootstrap method as described in section 10.2 from the book [Computer Age Statistical Inference by B.Efron and T.Hastie](https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf) that we linked earlier. We give an example of this in the next and last notebook. Note that there will be nothing for you to do in this last notebook. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-nYt5_h77QGN",
    "MzvvNPjWL5_-"
   ],
   "name": "M3_Practice_3_Evaluate fairness metrics with aif360.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "73a16743b82ab9faac55a58e515ab79ac0188679cca61a3332a4699caeaf409e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
