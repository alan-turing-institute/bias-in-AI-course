{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzgpJmDOSDfR"
      },
      "source": [
        "# **Pre-processing technique: Reweighing for Statistical Parity**\n",
        "\n",
        "Reweighing (Kamiran and Calders, 2012) is a pre-processing technique that amends the dataset to achieve statistical parity. The steps we will take are outlined below.\n",
        "\n",
        "1. First, we will calculate Disparate Impact and Statistical Parity Difference metrics for our training dataset\n",
        "2. Before we start using a predictive model, we will use the Reweighing technique on the full dataset just to explore how it works. This step should show that with the calculated weights assigned to the dataset, disparate impact and statistical parity difference are both removed. \n",
        "3. We will then apply the Reweighing method to data used to train a predictive model and observe the results.\n",
        "\n",
        "This notebook contains gaps in the code for you to fill in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaV6sRojLqem"
      },
      "source": [
        "# Install Libraries and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KwY66NktyspI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: holisticai in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (0.1.2)\n",
            "Requirement already satisfied: seaborn>=0.11.2 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from holisticai) (0.12.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from holisticai) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.23.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.9.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (3.1.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from seaborn>=0.11.2->holisticai) (1.4.4)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from seaborn>=0.11.2->holisticai) (3.5.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (9.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (4.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (21.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from pandas>=0.25->seaborn>=0.11.2->holisticai) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.1->seaborn>=0.11.2->holisticai) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# install holisticai\n",
        "!pip install holisticai\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "from holisticai.bias.mitigation import Reweighing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NnCNsoTLdHX"
      },
      "source": [
        "Load the data into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1RoDxmC_wh9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/l1/g77ghb8d3xg695jfbbdfjgdc0000gn/T/ipykernel_50778/3827542684.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Ethnicity_White'] = (df['Ethnicity'] == 'White')*1\n",
            "/var/folders/l1/g77ghb8d3xg695jfbbdfjgdc0000gn/T/ipykernel_50778/3827542684.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Ethnicity_Black'] = (df['Ethnicity'] == 'Black')*1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>Ethnicity_White</th>\n",
              "      <th>Ethnicity_Black</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.178832</td>\n",
              "      <td>0.147077</td>\n",
              "      <td>0.775331</td>\n",
              "      <td>-0.427889</td>\n",
              "      <td>0.640818</td>\n",
              "      <td>-0.610427</td>\n",
              "      <td>-1.023371</td>\n",
              "      <td>1.431524</td>\n",
              "      <td>1.459619</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.355889</td>\n",
              "      <td>-0.465837</td>\n",
              "      <td>-2.832634</td>\n",
              "      <td>0.917297</td>\n",
              "      <td>-0.241052</td>\n",
              "      <td>-2.122105</td>\n",
              "      <td>0.253170</td>\n",
              "      <td>0.164617</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.092276</td>\n",
              "      <td>0.122023</td>\n",
              "      <td>0.482935</td>\n",
              "      <td>-0.232131</td>\n",
              "      <td>-1.939064</td>\n",
              "      <td>-1.140216</td>\n",
              "      <td>-0.833250</td>\n",
              "      <td>-1.281904</td>\n",
              "      <td>0.228971</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.417751</td>\n",
              "      <td>1.254152</td>\n",
              "      <td>0.631731</td>\n",
              "      <td>1.665469</td>\n",
              "      <td>-0.388293</td>\n",
              "      <td>-0.804782</td>\n",
              "      <td>-0.227182</td>\n",
              "      <td>0.412375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.703377</td>\n",
              "      <td>-0.962149</td>\n",
              "      <td>-0.785495</td>\n",
              "      <td>-0.633902</td>\n",
              "      <td>-0.334718</td>\n",
              "      <td>-1.555958</td>\n",
              "      <td>0.825006</td>\n",
              "      <td>0.274443</td>\n",
              "      <td>1.448419</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079523</td>\n",
              "      <td>-0.932425</td>\n",
              "      <td>-0.693293</td>\n",
              "      <td>-0.114197</td>\n",
              "      <td>-1.252067</td>\n",
              "      <td>0.834270</td>\n",
              "      <td>-0.463270</td>\n",
              "      <td>0.559294</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.363013</td>\n",
              "      <td>1.264307</td>\n",
              "      <td>1.667603</td>\n",
              "      <td>0.903941</td>\n",
              "      <td>-0.062840</td>\n",
              "      <td>0.680886</td>\n",
              "      <td>0.389930</td>\n",
              "      <td>-0.000803</td>\n",
              "      <td>-0.782676</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.311236</td>\n",
              "      <td>2.447118</td>\n",
              "      <td>1.127650</td>\n",
              "      <td>0.086733</td>\n",
              "      <td>-0.381553</td>\n",
              "      <td>0.209684</td>\n",
              "      <td>0.197809</td>\n",
              "      <td>-0.879914</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.152488</td>\n",
              "      <td>-0.731821</td>\n",
              "      <td>-0.167126</td>\n",
              "      <td>-1.193398</td>\n",
              "      <td>1.180502</td>\n",
              "      <td>0.469656</td>\n",
              "      <td>-0.044317</td>\n",
              "      <td>-0.409883</td>\n",
              "      <td>0.625990</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.298833</td>\n",
              "      <td>2.067846</td>\n",
              "      <td>0.304233</td>\n",
              "      <td>-0.160228</td>\n",
              "      <td>1.017770</td>\n",
              "      <td>-1.002570</td>\n",
              "      <td>0.844326</td>\n",
              "      <td>-1.155311</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.706395</td>\n",
              "      <td>-0.435942</td>\n",
              "      <td>0.645464</td>\n",
              "      <td>-0.859816</td>\n",
              "      <td>0.914893</td>\n",
              "      <td>-0.022199</td>\n",
              "      <td>-0.424393</td>\n",
              "      <td>-0.976591</td>\n",
              "      <td>0.672857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.181203</td>\n",
              "      <td>0.367494</td>\n",
              "      <td>0.162101</td>\n",
              "      <td>-1.688369</td>\n",
              "      <td>-1.151553</td>\n",
              "      <td>0.777658</td>\n",
              "      <td>-1.044357</td>\n",
              "      <td>-0.074341</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.057075</td>\n",
              "      <td>1.791513</td>\n",
              "      <td>-1.065756</td>\n",
              "      <td>-0.783341</td>\n",
              "      <td>-0.559215</td>\n",
              "      <td>1.042646</td>\n",
              "      <td>-1.154058</td>\n",
              "      <td>1.094753</td>\n",
              "      <td>1.968674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021583</td>\n",
              "      <td>1.718576</td>\n",
              "      <td>1.171804</td>\n",
              "      <td>0.430075</td>\n",
              "      <td>3.340726</td>\n",
              "      <td>1.349216</td>\n",
              "      <td>1.481516</td>\n",
              "      <td>0.070563</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.582066</td>\n",
              "      <td>0.086788</td>\n",
              "      <td>0.167259</td>\n",
              "      <td>-1.672798</td>\n",
              "      <td>1.537135</td>\n",
              "      <td>-1.113315</td>\n",
              "      <td>0.222907</td>\n",
              "      <td>-1.743083</td>\n",
              "      <td>-0.086986</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072920</td>\n",
              "      <td>-1.841719</td>\n",
              "      <td>-0.807065</td>\n",
              "      <td>-0.793955</td>\n",
              "      <td>-1.098300</td>\n",
              "      <td>-1.474154</td>\n",
              "      <td>-0.828826</td>\n",
              "      <td>-0.891166</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.355098</td>\n",
              "      <td>-0.321228</td>\n",
              "      <td>-0.204290</td>\n",
              "      <td>0.498632</td>\n",
              "      <td>1.634130</td>\n",
              "      <td>0.847070</td>\n",
              "      <td>-0.552140</td>\n",
              "      <td>-1.614727</td>\n",
              "      <td>2.337347</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.781911</td>\n",
              "      <td>0.275032</td>\n",
              "      <td>0.690859</td>\n",
              "      <td>0.666878</td>\n",
              "      <td>0.644440</td>\n",
              "      <td>0.127891</td>\n",
              "      <td>1.277781</td>\n",
              "      <td>-0.744428</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.526557</td>\n",
              "      <td>2.174463</td>\n",
              "      <td>-0.979082</td>\n",
              "      <td>-0.681536</td>\n",
              "      <td>-0.145515</td>\n",
              "      <td>1.703135</td>\n",
              "      <td>0.947010</td>\n",
              "      <td>0.462636</td>\n",
              "      <td>0.271432</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.570147</td>\n",
              "      <td>0.861712</td>\n",
              "      <td>-0.939181</td>\n",
              "      <td>0.090775</td>\n",
              "      <td>-1.153183</td>\n",
              "      <td>-1.362903</td>\n",
              "      <td>-1.424866</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8762 rows Ã— 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label         0         1         2         3         4         5  \\\n",
              "0       1.0 -0.178832  0.147077  0.775331 -0.427889  0.640818 -0.610427   \n",
              "1       1.0  0.092276  0.122023  0.482935 -0.232131 -1.939064 -1.140216   \n",
              "2       0.0 -1.703377 -0.962149 -0.785495 -0.633902 -0.334718 -1.555958   \n",
              "4       1.0 -0.363013  1.264307  1.667603  0.903941 -0.062840  0.680886   \n",
              "5       0.0  0.152488 -0.731821 -0.167126 -1.193398  1.180502  0.469656   \n",
              "...     ...       ...       ...       ...       ...       ...       ...   \n",
              "9994    0.0 -1.706395 -0.435942  0.645464 -0.859816  0.914893 -0.022199   \n",
              "9995    1.0 -0.057075  1.791513 -1.065756 -0.783341 -0.559215  1.042646   \n",
              "9996    1.0  0.582066  0.086788  0.167259 -1.672798  1.537135 -1.113315   \n",
              "9997    0.0 -1.355098 -0.321228 -0.204290  0.498632  1.634130  0.847070   \n",
              "9998    1.0 -0.526557  2.174463 -0.979082 -0.681536 -0.145515  1.703135   \n",
              "\n",
              "             6         7         8  ...        42        43        44  \\\n",
              "0    -1.023371  1.431524  1.459619  ... -0.355889 -0.465837 -2.832634   \n",
              "1    -0.833250 -1.281904  0.228971  ... -1.417751  1.254152  0.631731   \n",
              "2     0.825006  0.274443  1.448419  ...  0.079523 -0.932425 -0.693293   \n",
              "4     0.389930 -0.000803 -0.782676  ... -0.311236  2.447118  1.127650   \n",
              "5    -0.044317 -0.409883  0.625990  ... -0.298833  2.067846  0.304233   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9994 -0.424393 -0.976591  0.672857  ...  0.181203  0.367494  0.162101   \n",
              "9995 -1.154058  1.094753  1.968674  ...  0.021583  1.718576  1.171804   \n",
              "9996  0.222907 -1.743083 -0.086986  ... -0.072920 -1.841719 -0.807065   \n",
              "9997 -0.552140 -1.614727  2.337347  ... -1.781911  0.275032  0.690859   \n",
              "9998  0.947010  0.462636  0.271432  ... -1.570147  0.861712 -0.939181   \n",
              "\n",
              "            45        46        47        48        49  Ethnicity_White  \\\n",
              "0     0.917297 -0.241052 -2.122105  0.253170  0.164617                0   \n",
              "1     1.665469 -0.388293 -0.804782 -0.227182  0.412375                0   \n",
              "2    -0.114197 -1.252067  0.834270 -0.463270  0.559294                0   \n",
              "4     0.086733 -0.381553  0.209684  0.197809 -0.879914                0   \n",
              "5    -0.160228  1.017770 -1.002570  0.844326 -1.155311                0   \n",
              "...        ...       ...       ...       ...       ...              ...   \n",
              "9994 -1.688369 -1.151553  0.777658 -1.044357 -0.074341                0   \n",
              "9995  0.430075  3.340726  1.349216  1.481516  0.070563                0   \n",
              "9996 -0.793955 -1.098300 -1.474154 -0.828826 -0.891166                0   \n",
              "9997  0.666878  0.644440  0.127891  1.277781 -0.744428                1   \n",
              "9998  0.090775 -1.153183 -1.362903 -1.424866 -0.374579                1   \n",
              "\n",
              "      Ethnicity_Black  \n",
              "0                   1  \n",
              "1                   0  \n",
              "2                   0  \n",
              "4                   0  \n",
              "5                   1  \n",
              "...               ...  \n",
              "9994                0  \n",
              "9995                0  \n",
              "9996                1  \n",
              "9997                0  \n",
              "9998                0  \n",
              "\n",
              "[8762 rows x 53 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load data\n",
        "from sklearn.datasets import fetch_openml\n",
        "bunch = fetch_openml(data_id=44270)\n",
        "df = bunch['frame'].dropna()\n",
        "df['Ethnicity_White'] = (df['Ethnicity'] == 'White')*1\n",
        "df['Ethnicity_Black'] = (df['Ethnicity'] == 'Black')*1\n",
        "df = df.drop(columns = ['Gender', 'Ethnicity'])\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ethnicity_White', 'Ethnicity_Black']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prot_cols = ['Ethnicity_White', 'Ethnicity_Black']\n",
        "prot_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n7MJE-ANcGN"
      },
      "source": [
        "## Calculate unwanted historic bias in our training data\n",
        "\n",
        "Using holisticai library, compute Disparate Impact and Statistical Parity Difference. Display a table showing the two metrics, alongside their target value (1 for Disparate Impact, 0 for Statistical Parity Difference)\n",
        "\n",
        "Use the holisticai documentation : https://holisticai.readthedocs.io/en/latest/metrics.html#binary-classificationhttps://holisticai.readthedocs.io/en/latest/metrics.html#binary-classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoMgYzwaNOzY"
      },
      "source": [
        "Set up variables for the privileged and unprivileged groups. In this example we will assign 'White' as our privileged group and 'Black' as unpriviledged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "nw_qyPNJGB6d",
        "outputId": "0d243243-633f-4806-a7c1-fdc38abfaae3"
      },
      "outputs": [],
      "source": [
        "# Compute Disparate Impact and Statistical Parity Difference metrics for the original dataset, without Reweighing\n",
        "from holisticai.bias import metrics as bias_metrics\n",
        "\n",
        "# Set up variables for the privileged and unprivileged groups\n",
        "\n",
        "group_a = df.Ethnicity_Black == 1\n",
        "group_b = df.Ethnicity_White == 1\n",
        "y = df.Label\n",
        "\n",
        "\n",
        "# TODO: Compute fairness metrics on the original dataset without Reweighing\n",
        "\n",
        "# /TODO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoM4yTLiRXir"
      },
      "source": [
        "# Apply Reweighing to the full dataset\n",
        "Now, use the [Reweighing](https://holisticai.readthedocs.io/en/latest/generated/holisticai.bias.mitigation.Reweighing.html#holisticai.bias.mitigation.Reweighing) technique to assign weights to each training data tuple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_ = df.drop(columns=[\"Label\"])\n",
        "y_ = df.Label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42)\n",
        "\n",
        "group_a = X_.Ethnicity_Black == 1\n",
        "group_b = X_.Ethnicity_White == 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0r4IL47MCk1"
      },
      "outputs": [],
      "source": [
        "# instantiate\n",
        "rew = Reweighing()\n",
        "\n",
        "# TODO: Use Reweighing to assign weights to each training data tuple\n",
        "\n",
        "# /TODO: Display the sample weights\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9kLf_pUSuCp"
      },
      "source": [
        "# Run a baseline predictive model without applying reweighing\n",
        "Now, we will build a standard Ridge Classifier and observe some baseline results, using the original data without Reweighing. \n",
        "\n",
        "Train a Ridge Classifier with 10 fold stratified cross validation. Compute performance metrics (Accuracy, Precision, Recall and F1 Score) and fairness metrics (Average Odds Difference, Equal Opportunity Difference, Disparate Impact, Statistical Parity Difference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Veury9HcNEeR"
      },
      "outputs": [],
      "source": [
        "# Instantiate the classifier\n",
        "\n",
        "model = RidgeClassifier(random_state=42)\n",
        "\n",
        "# instantiate the cross-validation scheme\n",
        "mv = StratifiedKFold(n_splits=10, shuffle=True, random_state=10)\n",
        "\n",
        "# setup the performance metrics to be computed\n",
        "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
        "                \"Precision\": metrics.precision_score, \n",
        "                \"Recall\": metrics.recall_score, \n",
        "                \"F1-Score\": metrics.f1_score, \n",
        "                }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDDMnHRmPtZk"
      },
      "outputs": [],
      "source": [
        "# Train a ridge regression classifier on the dataset before reweighing (this code is ready to run, there are no gaps to fill)\n",
        "k, i = True, 1\n",
        "\n",
        "# instantiating X\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "\n",
        "# instantiating the target variable\n",
        "y = df['Label']\n",
        "\n",
        "for (train, test) in mv.split(X, y):\n",
        "    # inst model\n",
        "    model = RidgeClassifier(random_state=10)\n",
        "\n",
        "    # instantiating X\n",
        "    X_train = X.iloc[train].copy()\n",
        "\n",
        "    # instantiating y\n",
        "    y_train = y.iloc[train].copy()\n",
        "\n",
        "    # fit model NOT including sample weights calculated in reweighing\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # X_test \n",
        "    X_test = X.iloc[test]\n",
        "    \n",
        "    # set up vectors\n",
        "    group_a = X_test.Ethnicity_Black == 1\n",
        "    group_b = X_test.Ethnicity_White == 1\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_true = y.iloc[test].values.ravel()\n",
        "    params = [group_a, group_b, y_pred]\n",
        "\n",
        "    # compute performance metrics\n",
        "    metric_list = []\n",
        "    for pf in perf_metrics.keys():\n",
        "            metric_list += [[pf, perf_metrics[pf](y_true, y_pred)]]\n",
        "    \n",
        "    # Compute fairness metrics\n",
        "    metric_list += [['Statistical Parity Difference', bias_metrics.statistical_parity(group_a, group_b, y_pred)]]\n",
        "    metric_list += [['Disparate Impact', bias_metrics.disparate_impact(group_a, group_b, y_pred)]]\n",
        "    metric_list += [['Equalized Odds Difference', bias_metrics.average_odds_diff(group_a, group_b, y_pred,y_true)]]\n",
        "    metric_list += [['False Negative Rate Difference', bias_metrics.false_negative_rate_diff(group_a, group_b, y_pred,y_true)]]\n",
        "\n",
        "    # concatenate results\n",
        "    df_m = pd.DataFrame(metric_list, columns=[\"Metric\", \"Value\"])\n",
        "    df_m[\"Fold\"] = i\n",
        "    i += 1\n",
        "    if k:\n",
        "        df_metrics_orig = df_m.copy()\n",
        "        k=0\n",
        "    else:\n",
        "        df_metrics_orig = pd.concat([df_metrics_orig, df_m.copy()], axis=0, ignore_index=True)\n",
        "\n",
        "df_metrics_orig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "WykgeYwFQZGd",
        "outputId": "55b5aa5d-1ffd-4f23-c61e-dae53a01e1a1"
      },
      "outputs": [],
      "source": [
        "# Display metrics\n",
        "\n",
        "metrics_table_orig = df_metrics_orig.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
        "metrics_table_orig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJOxrqbNvto2"
      },
      "source": [
        "# Use Reweighing algorithm to train a predictive model\n",
        "\n",
        "Amend your Ridge Classifier routine above to apply Reweighing to each fold of training data. Do not apply Reweighing at test time. Compute performance metrics (Accuracy, Precision, Recall and F1 Score) and fairness metrics (Average Odds Difference, Equal Opportunity Difference, Disparate Impact, Statistical Parity Difference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate the classifier\n",
        "\n",
        "model = RidgeClassifier()\n",
        "\n",
        "# instantiate the cross-validation scheme\n",
        "mv = StratifiedKFold(n_splits=10, shuffle=True, random_state=10)\n",
        "\n",
        "# setup the performance metrics to be computed\n",
        "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
        "                \"Precision\": metrics.precision_score, \n",
        "                \"Recall\": metrics.recall_score, \n",
        "                \"F1-Score\": metrics.f1_score, \n",
        "                }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "001wC_i8N0M-"
      },
      "outputs": [],
      "source": [
        "# Train a ridge regression classifier on the dataset before reweighing (this code is ready to run, there are no gaps to fill)\n",
        "k, i = True, 1\n",
        "\n",
        "# instantiating X\n",
        "X = df.drop(columns=[\"Label\"])\n",
        "\n",
        "# instantiating the target variable\n",
        "y = df.Label\n",
        "\n",
        "\n",
        "for (train, test) in mv.split(X, y):\n",
        "    model = RidgeClassifier()\n",
        "\n",
        "    # instantiating X\n",
        "    X_train = X.iloc[train].copy()\n",
        "\n",
        "    # instantiating y\n",
        "    y_train = y.iloc[train].copy()\n",
        "\n",
        "    # set up vectors\n",
        "    group_a = X_train.Ethnicity_Black == 1\n",
        "    group_b = X_train.Ethnicity_White == 1\n",
        "\n",
        "    # TODO compute Reweighing sample weights\n",
        "\n",
        "    #/ TODO\n",
        "\n",
        "    # TODO fit model including sample weights calculated in reweighing\n",
        "    \n",
        "    #/ TODO\n",
        "\n",
        "    # X_test \n",
        "    X_test = X.iloc[test]\n",
        "    \n",
        "    # set up vectors\n",
        "    group_a = X_test.Ethnicity_Black == 1\n",
        "    group_b = X_test.Ethnicity_White == 1\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_true = y.iloc[test].values.ravel()\n",
        "    params = [group_a, group_b, y_pred]\n",
        "\n",
        "    # compute performance metrics\n",
        "    metric_list = []\n",
        "    for pf in perf_metrics.keys():\n",
        "            metric_list += [[pf, perf_metrics[pf](y_true, y_pred)]]\n",
        "    \n",
        "    # Compute fairness metrics\n",
        "    metric_list += [['Statistical Parity Difference', bias_metrics.statistical_parity(*params)]]\n",
        "    metric_list += [['Disparate Impact', bias_metrics.disparate_impact(*params)]]\n",
        "    metric_list += [['Equalized Odds Difference', bias_metrics.average_odds_diff(*params,y_true)]]\n",
        "    metric_list += [['False Negative Rate Difference', bias_metrics.false_negative_rate_diff(*params,y_true)]]\n",
        "\n",
        "    # concatenate results\n",
        "    df_m = pd.DataFrame(metric_list, columns=[\"Metric\", \"Value\"])\n",
        "    df_m[\"Fold\"] = i\n",
        "    i += 1\n",
        "    if k:\n",
        "        df_metrics_rw = df_m.copy()\n",
        "        k=0\n",
        "    else:\n",
        "        df_metrics_rw = pd.concat([df_metrics_rw, df_m.copy()], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "hIq9sP3FO8lO",
        "outputId": "bdf5fe80-0fba-43f0-83a1-4a82eec58bf8"
      },
      "outputs": [],
      "source": [
        "# TODO: Display metrics\n",
        "\n",
        "# /TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuYBVBoywMyh"
      },
      "source": [
        "# Present results to show the effectiveness of the Reweighing method\n",
        "\n",
        "Present graphs (bar charts work well) to show how each performance and fairness metric differs for the baseline model compared with the application of Reweighing. Show the target line for each metric on the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FApym7uMzeha",
        "outputId": "1733bbb0-2f86-4a41-fa2c-1d6b7521eeba"
      },
      "outputs": [],
      "source": [
        "# TODO: Present graphs to show each performance and fairness metrics\n",
        "\n",
        "# /TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('torch-nightly')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f5fa74478a026ac530ef194e4df855dfb9675779484e20284ae5f690a2266d7b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
