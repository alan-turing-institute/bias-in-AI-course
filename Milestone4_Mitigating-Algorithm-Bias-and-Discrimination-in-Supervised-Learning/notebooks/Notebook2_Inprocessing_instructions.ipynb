{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzgpJmDOSDfR"
      },
      "source": [
        "# **In-processing technique: A Reductions Approach to Fairness for Statistical Parity**\n",
        "\n",
        "The Reductions approach (Agarwal et al 2018) makes use of constrained optimisation to reduce binary classification to a series of cost-sensitive, weighted classification problems. The optimal solution is then an equilibrium between two min max expressions. The steps we will take are outlined below.\n",
        "\n",
        "1. First, we will calculate fairness metrics for a base classifier\n",
        "2. We will then apply the Reductions method to train a predictive model and observe the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaV6sRojLqem"
      },
      "source": [
        "# Install Libraries and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KwY66NktyspI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: holisticai in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (0.1.2)\n",
            "Requirement already satisfied: seaborn>=0.11.2 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from holisticai) (0.12.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from holisticai) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.23.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.9.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from scikit-learn>=1.0.2->holisticai) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from seaborn>=0.11.2->holisticai) (3.5.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from seaborn>=0.11.2->holisticai) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (4.34.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (9.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from matplotlib>=3.1->seaborn>=0.11.2->holisticai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from pandas>=0.25->seaborn>=0.11.2->holisticai) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/giuliofilippi/opt/anaconda3/envs/torch-nightly/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.1->seaborn>=0.11.2->holisticai) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# install hai library\n",
        "!pip install holisticai\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "from holisticai.bias.mitigation import ExponentiatedGradientReduction\n",
        "from holisticai.bias import metrics as bias_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NnCNsoTLdHX"
      },
      "source": [
        "Load the data into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1RoDxmC_wh9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>Ethnicity_White</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.178832</td>\n",
              "      <td>0.147077</td>\n",
              "      <td>0.775331</td>\n",
              "      <td>-0.427889</td>\n",
              "      <td>0.640818</td>\n",
              "      <td>-0.610427</td>\n",
              "      <td>-1.023371</td>\n",
              "      <td>1.431524</td>\n",
              "      <td>1.459619</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.042387</td>\n",
              "      <td>-0.355889</td>\n",
              "      <td>-0.465837</td>\n",
              "      <td>-2.832634</td>\n",
              "      <td>0.917297</td>\n",
              "      <td>-0.241052</td>\n",
              "      <td>-2.122105</td>\n",
              "      <td>0.253170</td>\n",
              "      <td>0.164617</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.092276</td>\n",
              "      <td>0.122023</td>\n",
              "      <td>0.482935</td>\n",
              "      <td>-0.232131</td>\n",
              "      <td>-1.939064</td>\n",
              "      <td>-1.140216</td>\n",
              "      <td>-0.833250</td>\n",
              "      <td>-1.281904</td>\n",
              "      <td>0.228971</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750136</td>\n",
              "      <td>-1.417751</td>\n",
              "      <td>1.254152</td>\n",
              "      <td>0.631731</td>\n",
              "      <td>1.665469</td>\n",
              "      <td>-0.388293</td>\n",
              "      <td>-0.804782</td>\n",
              "      <td>-0.227182</td>\n",
              "      <td>0.412375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.703377</td>\n",
              "      <td>-0.962149</td>\n",
              "      <td>-0.785495</td>\n",
              "      <td>-0.633902</td>\n",
              "      <td>-0.334718</td>\n",
              "      <td>-1.555958</td>\n",
              "      <td>0.825006</td>\n",
              "      <td>0.274443</td>\n",
              "      <td>1.448419</td>\n",
              "      <td>...</td>\n",
              "      <td>0.368800</td>\n",
              "      <td>0.079523</td>\n",
              "      <td>-0.932425</td>\n",
              "      <td>-0.693293</td>\n",
              "      <td>-0.114197</td>\n",
              "      <td>-1.252067</td>\n",
              "      <td>0.834270</td>\n",
              "      <td>-0.463270</td>\n",
              "      <td>0.559294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.363013</td>\n",
              "      <td>1.264307</td>\n",
              "      <td>1.667603</td>\n",
              "      <td>0.903941</td>\n",
              "      <td>-0.062840</td>\n",
              "      <td>0.680886</td>\n",
              "      <td>0.389930</td>\n",
              "      <td>-0.000803</td>\n",
              "      <td>-0.782676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.784050</td>\n",
              "      <td>-0.311236</td>\n",
              "      <td>2.447118</td>\n",
              "      <td>1.127650</td>\n",
              "      <td>0.086733</td>\n",
              "      <td>-0.381553</td>\n",
              "      <td>0.209684</td>\n",
              "      <td>0.197809</td>\n",
              "      <td>-0.879914</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.152488</td>\n",
              "      <td>-0.731821</td>\n",
              "      <td>-0.167126</td>\n",
              "      <td>-1.193398</td>\n",
              "      <td>1.180502</td>\n",
              "      <td>0.469656</td>\n",
              "      <td>-0.044317</td>\n",
              "      <td>-0.409883</td>\n",
              "      <td>0.625990</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.292245</td>\n",
              "      <td>-0.298833</td>\n",
              "      <td>2.067846</td>\n",
              "      <td>0.304233</td>\n",
              "      <td>-0.160228</td>\n",
              "      <td>1.017770</td>\n",
              "      <td>-1.002570</td>\n",
              "      <td>0.844326</td>\n",
              "      <td>-1.155311</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.706395</td>\n",
              "      <td>-0.435942</td>\n",
              "      <td>0.645464</td>\n",
              "      <td>-0.859816</td>\n",
              "      <td>0.914893</td>\n",
              "      <td>-0.022199</td>\n",
              "      <td>-0.424393</td>\n",
              "      <td>-0.976591</td>\n",
              "      <td>0.672857</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.377802</td>\n",
              "      <td>0.181203</td>\n",
              "      <td>0.367494</td>\n",
              "      <td>0.162101</td>\n",
              "      <td>-1.688369</td>\n",
              "      <td>-1.151553</td>\n",
              "      <td>0.777658</td>\n",
              "      <td>-1.044357</td>\n",
              "      <td>-0.074341</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.057075</td>\n",
              "      <td>1.791513</td>\n",
              "      <td>-1.065756</td>\n",
              "      <td>-0.783341</td>\n",
              "      <td>-0.559215</td>\n",
              "      <td>1.042646</td>\n",
              "      <td>-1.154058</td>\n",
              "      <td>1.094753</td>\n",
              "      <td>1.968674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.709753</td>\n",
              "      <td>0.021583</td>\n",
              "      <td>1.718576</td>\n",
              "      <td>1.171804</td>\n",
              "      <td>0.430075</td>\n",
              "      <td>3.340726</td>\n",
              "      <td>1.349216</td>\n",
              "      <td>1.481516</td>\n",
              "      <td>0.070563</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.582066</td>\n",
              "      <td>0.086788</td>\n",
              "      <td>0.167259</td>\n",
              "      <td>-1.672798</td>\n",
              "      <td>1.537135</td>\n",
              "      <td>-1.113315</td>\n",
              "      <td>0.222907</td>\n",
              "      <td>-1.743083</td>\n",
              "      <td>-0.086986</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150314</td>\n",
              "      <td>-0.072920</td>\n",
              "      <td>-1.841719</td>\n",
              "      <td>-0.807065</td>\n",
              "      <td>-0.793955</td>\n",
              "      <td>-1.098300</td>\n",
              "      <td>-1.474154</td>\n",
              "      <td>-0.828826</td>\n",
              "      <td>-0.891166</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.355098</td>\n",
              "      <td>-0.321228</td>\n",
              "      <td>-0.204290</td>\n",
              "      <td>0.498632</td>\n",
              "      <td>1.634130</td>\n",
              "      <td>0.847070</td>\n",
              "      <td>-0.552140</td>\n",
              "      <td>-1.614727</td>\n",
              "      <td>2.337347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.688433</td>\n",
              "      <td>-1.781911</td>\n",
              "      <td>0.275032</td>\n",
              "      <td>0.690859</td>\n",
              "      <td>0.666878</td>\n",
              "      <td>0.644440</td>\n",
              "      <td>0.127891</td>\n",
              "      <td>1.277781</td>\n",
              "      <td>-0.744428</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.526557</td>\n",
              "      <td>2.174463</td>\n",
              "      <td>-0.979082</td>\n",
              "      <td>-0.681536</td>\n",
              "      <td>-0.145515</td>\n",
              "      <td>1.703135</td>\n",
              "      <td>0.947010</td>\n",
              "      <td>0.462636</td>\n",
              "      <td>0.271432</td>\n",
              "      <td>...</td>\n",
              "      <td>2.043764</td>\n",
              "      <td>-1.570147</td>\n",
              "      <td>0.861712</td>\n",
              "      <td>-0.939181</td>\n",
              "      <td>0.090775</td>\n",
              "      <td>-1.153183</td>\n",
              "      <td>-1.362903</td>\n",
              "      <td>-1.424866</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8762 rows Ã— 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label         0         1         2         3         4         5  \\\n",
              "0       1.0 -0.178832  0.147077  0.775331 -0.427889  0.640818 -0.610427   \n",
              "1       1.0  0.092276  0.122023  0.482935 -0.232131 -1.939064 -1.140216   \n",
              "2       0.0 -1.703377 -0.962149 -0.785495 -0.633902 -0.334718 -1.555958   \n",
              "4       1.0 -0.363013  1.264307  1.667603  0.903941 -0.062840  0.680886   \n",
              "5       0.0  0.152488 -0.731821 -0.167126 -1.193398  1.180502  0.469656   \n",
              "...     ...       ...       ...       ...       ...       ...       ...   \n",
              "9994    0.0 -1.706395 -0.435942  0.645464 -0.859816  0.914893 -0.022199   \n",
              "9995    1.0 -0.057075  1.791513 -1.065756 -0.783341 -0.559215  1.042646   \n",
              "9996    1.0  0.582066  0.086788  0.167259 -1.672798  1.537135 -1.113315   \n",
              "9997    0.0 -1.355098 -0.321228 -0.204290  0.498632  1.634130  0.847070   \n",
              "9998    1.0 -0.526557  2.174463 -0.979082 -0.681536 -0.145515  1.703135   \n",
              "\n",
              "             6         7         8  ...        41        42        43  \\\n",
              "0    -1.023371  1.431524  1.459619  ... -0.042387 -0.355889 -0.465837   \n",
              "1    -0.833250 -1.281904  0.228971  ...  0.750136 -1.417751  1.254152   \n",
              "2     0.825006  0.274443  1.448419  ...  0.368800  0.079523 -0.932425   \n",
              "4     0.389930 -0.000803 -0.782676  ...  0.784050 -0.311236  2.447118   \n",
              "5    -0.044317 -0.409883  0.625990  ... -1.292245 -0.298833  2.067846   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9994 -0.424393 -0.976591  0.672857  ... -0.377802  0.181203  0.367494   \n",
              "9995 -1.154058  1.094753  1.968674  ...  0.709753  0.021583  1.718576   \n",
              "9996  0.222907 -1.743083 -0.086986  ...  0.150314 -0.072920 -1.841719   \n",
              "9997 -0.552140 -1.614727  2.337347  ...  0.688433 -1.781911  0.275032   \n",
              "9998  0.947010  0.462636  0.271432  ...  2.043764 -1.570147  0.861712   \n",
              "\n",
              "            44        45        46        47        48        49  \\\n",
              "0    -2.832634  0.917297 -0.241052 -2.122105  0.253170  0.164617   \n",
              "1     0.631731  1.665469 -0.388293 -0.804782 -0.227182  0.412375   \n",
              "2    -0.693293 -0.114197 -1.252067  0.834270 -0.463270  0.559294   \n",
              "4     1.127650  0.086733 -0.381553  0.209684  0.197809 -0.879914   \n",
              "5     0.304233 -0.160228  1.017770 -1.002570  0.844326 -1.155311   \n",
              "...        ...       ...       ...       ...       ...       ...   \n",
              "9994  0.162101 -1.688369 -1.151553  0.777658 -1.044357 -0.074341   \n",
              "9995  1.171804  0.430075  3.340726  1.349216  1.481516  0.070563   \n",
              "9996 -0.807065 -0.793955 -1.098300 -1.474154 -0.828826 -0.891166   \n",
              "9997  0.690859  0.666878  0.644440  0.127891  1.277781 -0.744428   \n",
              "9998 -0.939181  0.090775 -1.153183 -1.362903 -1.424866 -0.374579   \n",
              "\n",
              "      Ethnicity_White  \n",
              "0                   0  \n",
              "1                   0  \n",
              "2                   0  \n",
              "4                   0  \n",
              "5                   0  \n",
              "...               ...  \n",
              "9994                0  \n",
              "9995                0  \n",
              "9996                0  \n",
              "9997                1  \n",
              "9998                1  \n",
              "\n",
              "[8762 rows x 52 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "# Load data\n",
        "from sklearn.datasets import fetch_openml\n",
        "bunch = fetch_openml(data_id=44270)\n",
        "df = bunch['frame'].dropna()\n",
        "df['Ethnicity_White'] = (df['Ethnicity'] == 'White')*1\n",
        "df = df.drop(columns = ['Gender', 'Ethnicity'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9kLf_pUSuCp"
      },
      "source": [
        "# Run a baseline predictive model without applying a fairness technique\n",
        "First we will build a standard Ridge Classifier and observe some baseline results, using the original data and without a fairness technique.\n",
        "\n",
        "Train a Ridge Classifier with 10 fold stratified cross validation. Compute performance metrics (Accuracy, Precision, Recall and F1 Score) and fairness metrics (Equalized Odds Difference, False Negative Rate Difference, and Statistical Parity Difference)\n",
        "\n",
        "This base code for the ridge regression classifier is provided for you. There are no gaps to fill in in this sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Veury9HcNEeR"
      },
      "outputs": [],
      "source": [
        "# Instantiate the classifier\n",
        "\n",
        "model = RidgeClassifier()\n",
        "\n",
        "# instantiate the cross-validation scheme\n",
        "mv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
        "\n",
        "# setup the performance metrics to be computed\n",
        "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
        "                \"Precision\": metrics.precision_score, \n",
        "                \"Recall\": metrics.recall_score, \n",
        "                \"F1-Score\": metrics.f1_score, \n",
        "                }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mDDMnHRmPtZk"
      },
      "outputs": [],
      "source": [
        "# Train a baseline ridge regression classifier on the dataset before applying the Reductions method\n",
        "k, i = True, 1\n",
        "\n",
        "# instantiating X\n",
        "X = df.drop(labels=['Label'], axis=1)\n",
        "\n",
        "# instantiating the target variable\n",
        "y = df['Label']\n",
        "\n",
        "# 10 fold CV\n",
        "for (train, test) in mv.split(X, y):\n",
        "\n",
        "    # fit model\n",
        "    X_train = X.iloc[train].copy()\n",
        "    y_train = y.iloc[train].copy()\n",
        "    model = model.fit(X_train, y_train)\n",
        "    \n",
        "    # get predictions in the test set\n",
        "\n",
        "    ypred_class = model.predict(X.iloc[test])\n",
        "\n",
        "    # compute performance metrics\n",
        "    metric_list = []\n",
        "    X_test = X.iloc[test].copy()\n",
        "    y_test = y.iloc[test].copy()\n",
        "    group_a = X_test.Ethnicity_White != 1\n",
        "    group_b = X_test.Ethnicity_White == 1\n",
        "    white = X_test['Ethnicity_White']\n",
        "    for pf in perf_metrics.keys():\n",
        "            metric_list += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
        "    spd = bias_metrics.statistical_parity(group_a, group_b, ypred_class)\n",
        "    eod = bias_metrics.average_odds_diff(group_a, group_b, ypred_class, y_test)\n",
        "    fnrd = bias_metrics.false_negative_rate_diff(group_a, group_b, ypred_class, y_test)\n",
        "    \n",
        "    # Compute fairness metrics\n",
        "    metric_list += [['Statistical Parity Difference', spd]]\n",
        "    metric_list += [['Equalized Odds Difference', eod]]\n",
        "    metric_list += [['False Negative Rate Difference', fnrd]]\n",
        "\n",
        "    # concatenate results\n",
        "    df_m = pd.DataFrame(metric_list, columns=[\"Metric\", \"Value\"])\n",
        "    df_m[\"Fold\"] = i\n",
        "    i += 1\n",
        "    if k:\n",
        "        df_metrics_orig = df_m.copy()\n",
        "        k=0\n",
        "    else:\n",
        "        df_metrics_orig = pd.concat([df_metrics_orig, df_m.copy()], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "WykgeYwFQZGd",
        "outputId": "131a33c2-1891-40cf-c9d7-d31029eba644"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Metric</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.706002</td>\n",
              "      <td>0.008056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Equalized Odds Difference</th>\n",
              "      <td>-0.058629</td>\n",
              "      <td>0.017678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1-Score</th>\n",
              "      <td>0.577810</td>\n",
              "      <td>0.011547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>False Negative Rate Difference</th>\n",
              "      <td>0.090245</td>\n",
              "      <td>0.032354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.630473</td>\n",
              "      <td>0.013622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.533434</td>\n",
              "      <td>0.014296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Statistical Parity Difference</th>\n",
              "      <td>-0.062992</td>\n",
              "      <td>0.019121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    mean       std\n",
              "                                   Value     Value\n",
              "Metric                                            \n",
              "Accuracy                        0.706002  0.008056\n",
              "Equalized Odds Difference      -0.058629  0.017678\n",
              "F1-Score                        0.577810  0.011547\n",
              "False Negative Rate Difference  0.090245  0.032354\n",
              "Precision                       0.630473  0.013622\n",
              "Recall                          0.533434  0.014296\n",
              "Statistical Parity Difference  -0.062992  0.019121"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display metrics\n",
        "\n",
        "metrics_table_orig = df_metrics_orig.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
        "metrics_table_orig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJOxrqbNvto2"
      },
      "source": [
        "# Use the Reductions approach to target Statistical Parity\n",
        "\n",
        "Amend your Ridge Classifier routine above to apply the [Reductions](https://holisticai.readthedocs.io/en/latest/generated/holisticai.bias.mitigation.ExponentiatedGradientReduction.html#holisticai.bias.mitigation.ExponentiatedGradientReduction) approach when training the model. Compute performance metrics (Accuracy, Precision, Recall and F1 Score) and fairness metrics (Equalized Odds Difference, False Negative Rate Difference, Statistical Parity Difference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "001wC_i8N0M-"
      },
      "outputs": [],
      "source": [
        "# Train a ridge regression classifier on the dataset with inprocessing\n",
        "model = RidgeClassifier()\n",
        "k, i = True, 1\n",
        "\n",
        "# instantiating X\n",
        "X = df.drop(labels=['Label'], axis=1)\n",
        "\n",
        "# instantiating the target variable\n",
        "y = df['Label']\n",
        "\n",
        "# 10 fold cv\n",
        "for (train, test) in mv.split(X, y):\n",
        "\n",
        "    # fit reductions in-processor\n",
        "    X_train = X.iloc[train].copy()\n",
        "    y_train = y.iloc[train].copy()\n",
        "    group_a = X_train.Ethnicity_White != 1\n",
        "    group_b = X_train.Ethnicity_White == 1\n",
        "\n",
        "    # TODO set up the in-processor\n",
        "\n",
        "\n",
        "    # TODO incorporate model in gsr\n",
        "\n",
        "\n",
        "    # TODO fit with data\n",
        "\n",
        "\n",
        "    # TODO get predictions in the test set\n",
        "\n",
        "\n",
        "    # compute performance metrics\n",
        "    metric_list = []\n",
        "    group_a = X_test.Ethnicity_White != 1\n",
        "    group_b = X_test.Ethnicity_White == 1\n",
        "    y_test = y.iloc[test].copy()\n",
        "    white = X_test['Ethnicity_White']\n",
        "    for pf in perf_metrics.keys():\n",
        "            metric_list += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
        "    spd = bias_metrics.statistical_parity(group_a, group_b, ypred_class)\n",
        "    eod = bias_metrics.average_odds_diff(group_a, group_b, ypred_class, y_test)\n",
        "    fnrd = bias_metrics.false_negative_rate_diff(group_a, group_b, ypred_class, y_test)\n",
        "    \n",
        "    # Compute fairness metrics\n",
        "    metric_list += [['Statistical Parity Difference', spd]]\n",
        "    metric_list += [['Equalized Odds Difference', eod]]\n",
        "    metric_list += [['False Negative Rate Difference', fnrd]]\n",
        "\n",
        "    # concatenate results\n",
        "    df_m = pd.DataFrame(metric_list, columns=[\"Metric\", \"Value\"])\n",
        "    df_m[\"Fold\"] = i\n",
        "    i += 1\n",
        "    if k:\n",
        "        df_metrics = df_m.copy()\n",
        "        k=0\n",
        "    else:\n",
        "        df_metrics = pd.concat([df_metrics, df_m.copy()], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "hIq9sP3FO8lO",
        "outputId": "d8b70be6-ba28-44f2-fa11-d77d777ac305"
      },
      "outputs": [],
      "source": [
        "# Display metrics\n",
        "\n",
        "metrics_table_rw = df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
        "metrics_table_rw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuYBVBoywMyh"
      },
      "source": [
        "# Present results to show the effectiveness of the Reductions method in Achieving Statistical Parity\n",
        "\n",
        "Present graphs (bar charts work well) to show how each performance and fairness metric differs for the baseline model compared with the application of the reductions method. Show the target line for each metric on the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FApym7uMzeha",
        "outputId": "9d6bfbc8-41c1-4a18-943e-6e4fe6c5220b"
      },
      "outputs": [],
      "source": [
        "# TODO: Present graphs\n",
        "\n",
        "# /TODO\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('torch-nightly')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f5fa74478a026ac530ef194e4df855dfb9675779484e20284ae5f690a2266d7b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
